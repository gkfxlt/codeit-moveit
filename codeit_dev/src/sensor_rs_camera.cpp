#include "sensor_rs_camera.hpp"#include <librealsense2/rs.hpp>#include <opencv2/core/core.hpp>#include <opencv2/opencv.hpp>#include <pcl/point_types.h>#include <pcl/point_cloud.h>#include <boost/smart_ptr.hpp>#include <boost/shared_ptr.hpp>#include <regex>#include <unordered_set>#include <vector>#include <string>namespace codeit::sensor {const uint16_t RS435_RGB_PID = 0x0b07;     // AWGCconst int IMAGE_WIDTH = 640;const int IMAGE_HEIGHT = 480;const bool ALIGN_DEPTH = true;const bool POINTCLOUD = true;const std::string DEFAULT_FILTERS = "";const std::vector<stream_index_pair> IMAGE_STREAMS = { DEPTH, COLOR };/** @brief implementation of split a string based on specified \a delimiters */static void split(const std::string& s,	std::vector<std::string>& tokens,	const std::string& delimiters = " ") {	std::string::size_type last_pos = s.find_first_not_of(delimiters, 0);	std::string::size_type pos = s.find_first_of(delimiters, last_pos);	while (std::string::npos != pos || std::string::npos != last_pos) {		tokens.push_back(s.substr(last_pos, pos - last_pos));		last_pos = s.find_first_not_of(delimiters, pos);		pos = s.find_first_of(delimiters, last_pos);	}}struct RsCameraDataParser::Imp {	std::unique_ptr<char[]> data_;	cv::Mat rgb_;	int rgb_width_ = -1;	int rgb_height_ = -1;	int rgb_elem_size_ = -1;	int rgb_size_ = -1;	cv::Mat depth_;	int depth_width_ = -1;	int depth_height_ = -1;	int depth_elem_size_ = -1;	int depth_size_ = -1;	int depth_offset_ = -1;	pcl::PointCloud<pcl::PointXYZ>::Ptr point_cloud_;	int pc_width_ = -1;	int pc_height_ = -1;	int pc_elem_size_ = -1;	int pc_size_ = -1;	int pc_offset_ = 1;	int total_size_ = -1;};RsCameraDataParser::RsCameraDataParser() : imp_(new Imp()) {}RsCameraDataParser::~RsCameraDataParser() = default;auto RsCameraDataParser::parseFrom(Sensor* sensor) -> bool {	auto* sens = dynamic_cast<SensorRsCamera*>(sensor);	if (!sens) {		return false;	}	if (needInit()) {		init(*sens);	}	sens->display<char>(imp_->data_[0]);		//memcpy(imp_->point_cloud_->points.data(), imp_->data_.get() + imp_->pc_offset_, imp_->pc_size_);	float* p = (float*)(imp_->data_.get() + imp_->pc_offset_);	for (size_t i = 0; i < imp_->point_cloud_->size(); ++i) {		imp_->point_cloud_->points[i].x = *p++;		imp_->point_cloud_->points[i].y = *p++;		imp_->point_cloud_->points[i].z = *p++;	}	return true;}auto RsCameraDataParser::copyTo(Sensor* sensor, stream_index_pair elem, rs2::frame& frame, core::Msg& data) -> bool {	auto* sens = dynamic_cast<SensorRsCamera*>(sensor);	if (needInit()) {		init(*sens);	}	if (data.size() != imp_->total_size_) {		sens->setLength(imp_->total_size_);		data.resize(imp_->total_size_);	}	if (elem == COLOR) {		memcpy(data.data(), frame.get_data(), imp_->rgb_size_);	}	else if (elem == DEPTH) {		memcpy(data.data() + imp_->depth_offset_, frame.get_data(), imp_->depth_size_);	}	else if (elem == POINT_CLOUD) {		memcpy(data.data() + imp_->pc_offset_, frame.get_data(), imp_->pc_size_);	}	return true;}auto RsCameraDataParser::rgb()->cv::Mat {	return imp_->rgb_;}auto RsCameraDataParser::depth()->cv::Mat {	return imp_->depth_;}auto RsCameraDataParser::needInit() -> bool {	return !imp_->data_;}auto RsCameraDataParser::pointCloud() -> pcl::PointCloud<pcl::PointXYZ>::ConstPtr {	return imp_->point_cloud_;}auto RsCameraDataParser::init(SensorRsCamera& rs_cam) -> void {	// initialize color stream from profile	rs2::video_stream_profile video_profile = rs_cam.getImageStreamProfile(COLOR);	imp_->rgb_elem_size_ = 3;	imp_->rgb_height_ = video_profile.height();	imp_->rgb_width_ = video_profile.width();	imp_->rgb_size_ = imp_->rgb_width_ * imp_->rgb_height_ * imp_->rgb_elem_size_;	imp_->depth_offset_ = imp_->rgb_size_;	// initialize depth stream from profile	video_profile = rs_cam.getImageStreamProfile(DEPTH);	imp_->depth_elem_size_ = 2;	imp_->depth_height_ = video_profile.height();	imp_->depth_width_ = video_profile.width();	imp_->depth_size_ = imp_->rgb_width_ * imp_->rgb_height_ * imp_->depth_elem_size_;	// initialize point cloud stream from profile	imp_->pc_elem_size_ = sizeof(float) * 3;	imp_->pc_height_ = imp_->depth_height_;	imp_->pc_width_ = imp_->depth_width_;	imp_->pc_size_ = imp_->pc_width_ * imp_->pc_height_ * imp_->pc_elem_size_;	imp_->pc_offset_ = imp_->depth_offset_ + imp_->depth_size_;	imp_->total_size_ = imp_->rgb_size_ + imp_->depth_size_ + imp_->pc_size_;	imp_->data_ = std::unique_ptr<char[]>(new char[imp_->total_size_]);	// initialize opencv Mat object	imp_->rgb_.create(imp_->rgb_height_, imp_->rgb_width_, CV_8UC3);	imp_->rgb_.data = (uint8_t*)(imp_->data_.get());	imp_->depth_.create(imp_->depth_height_, imp_->depth_width_, CV_16UC1);	imp_->depth_.data = (uint8_t*)(imp_->data_.get() + imp_->depth_offset_);	// initialize pcl point cloud object	imp_->point_cloud_ = boost::make_shared<pcl::PointCloud<pcl::PointXYZ>>();	imp_->point_cloud_->resize(imp_->pc_width_ * imp_->pc_height_);	imp_->point_cloud_->width = imp_->pc_width_;	imp_->point_cloud_->height = imp_->pc_height_;}/*** @class NamedFilter* @brief Used to do frameset filter*/class NamedFilter{public:	std::string name_;	std::shared_ptr<rs2::filter> filter_;public:	NamedFilter(std::string name, std::shared_ptr<rs2::filter> filter) :		name_(name), filter_(filter)	{}};struct SensorRsCamera::Imp {	/** @brief Initialize realsense camera */	bool initialize() {		if (!getDevice(context_.query_devices())) {			return false;		}		if (!setupDevice()) {			return false;		}		setupFilters();		if (!enableDevice()) {			return false;		}		return true;	}	/** @brief parse camera device */	bool getDevice(rs2::device_list list) {		if (device_) return true;		if (0 == list.size()) {			LOG_ERROR << "No RealSense devices were found!";			LOG_COUT << "No RealSense devices were found!";			return false;		}		for (Size count = 0; count < list.size(); ++count) {			rs2::device dev;			try {				dev = list[count];			}			catch (const std::exception& ex) {				LOG_WARN << "Device " << count + 1 << "/" << list.size()					<< " failed with exception: " << ex.what();				continue;			}			std::string sn(dev.get_info(RS2_CAMERA_INFO_SERIAL_NUMBER));			LOG_INFO << "Device with serial number " << sn << " was found."				<< std::endl;			LOG_COUT << "Device with serial number " << sn << " was found."				<< std::endl;			std::string pn = dev.get_info(RS2_CAMERA_INFO_PHYSICAL_PORT);			std::string name = dev.get_info(RS2_CAMERA_INFO_NAME);			if (sn == serial_no_) {				device_ = dev;				return true;			}		}		LOG_ERROR << "No specified device found." << endl;		LOG_COUT << "No specified device found." << endl;		return false;	}	/** @brief setup device, parser sensor and its' profiles */	bool setupDevice() {		const std::unordered_set<uint16_t> supported{ RS435_RGB_PID };		std::string pid_str(device_.get_info(RS2_CAMERA_INFO_PRODUCT_ID));		uint16_t pid = std::stoi(pid_str, 0, 16);		if (supported.count(pid) <= 0) {			LOG_ERROR << "Unsupported device!"				<< " Product ID: 0x" << pid_str << std::endl;			LOG_COUT << "Unsupported device!"				<< " Product ID: 0x" << pid_str << std::endl;			return false;		}		dev_sensors_ = device_.query_sensors();		// parse sensor profiles		for (auto& sensor : dev_sensors_) {			for (auto& profile : sensor.get_stream_profiles()) {				auto video_profile = profile.as<rs2::video_stream_profile>();				stream_index_pair sip(video_profile.stream_type(), video_profile.stream_index());				if (sensors_.find(sip) != sensors_.end()) continue;				sensors_[sip] = sensor;			}		}		return true;	}	/** @brief Enable streams and start pipeline */	bool enableDevice() {		try {			rs2::config config;			config.disable_all_streams();			for (auto& elem : IMAGE_STREAMS) {				auto& sens = sensors_[elem];				auto profiles = sens.get_stream_profiles();				rs2::stream_profile default_profile, selected_profile;				// find profile for stream				for (auto& profile : profiles) {					auto video_profile = profile.as<rs2::video_stream_profile>();					if (profile.stream_type() == elem.first && profile.stream_index() == elem.second) {						if (profile.is_default()) {							default_profile = profile;						}						if ((width_[elem] == 0 || video_profile.width() == width_[elem]) &&							(height_[elem] == 0 || video_profile.height() == height_[elem]) &&							(fps_[elem] == 0 || video_profile.fps() == fps_[elem]) &&							(format_.find(elem.first) == format_.end() || video_profile.format() == format_[elem.first])) {							selected_profile = profile;							break;						}					}				}				if (!selected_profile) {					if (default_profile) {						selected_profile = default_profile;					}				}				// enable stream from selected profile				if (selected_profile) {					auto video_profile = selected_profile.as<rs2::video_stream_profile>();					width_[elem] = video_profile.width();					height_[elem] = video_profile.height();					fps_[elem] = video_profile.fps();					image_[elem] = cv::Mat(height_[elem], width_[elem], image_format_[elem.first], cv::Scalar(0, 0, 0));					enabled_profiles_[elem].push_back(selected_profile);					config.enable_stream(elem.first, elem.second, width_[elem], height_[elem], format_[elem.first], fps_[elem]);				}			}			// enable device and start the pipeline			config.enable_device(serial_no_);			pipe_.start(config);			return true;		}		catch (rs2::error& e) {			LOG_ERROR << "Exception: " << e.what() << std::endl;			LOG_COUT << "Exception: " << e.what() << std::endl;			return false;		}	}	/** @brief setup filters for frameset */	void setupFilters() {		std::vector<std::string> filters_str;		split(filters_str_, filters_str, ",");		bool use_disparity_filter(false);		bool use_colorizer_filter(false);		bool use_decimation_filter(false);		for (auto s_iter = filters_str.begin(); s_iter != filters_str.end(); ++s_iter) {			if (*s_iter == "colorizer") {				use_colorizer_filter = true;			}			else if (*s_iter == "disparity") {				use_disparity_filter = true;			}			else if (*s_iter == "spatial") {				filters_.push_back(NamedFilter("spatial", std::make_shared<rs2::spatial_filter>()));			}			else if (*s_iter == "temporal") {				filters_.push_back(NamedFilter("temporal", std::make_shared<rs2::temporal_filter>()));			}			else if (*s_iter == "hole_filling") {				filters_.push_back(NamedFilter("hole_filling", std::make_shared<rs2::hole_filling_filter>()));			}			else if (*s_iter == "decimation") {				use_decimation_filter = true;			}			else if (s_iter->size() > 0) {				LOG_ERROR << "Unknown Filter: " << (*s_iter) << endl;				LOG_COUT << "Unknown Filter: " << (*s_iter) << endl;			}		}		if (use_disparity_filter) {			filters_.insert(filters_.begin(), NamedFilter("disparity_start", std::make_shared<rs2::disparity_transform>()));			filters_.push_back(NamedFilter("disparity_end", std::make_shared<rs2::disparity_transform>(false)));		}		if (use_decimation_filter) {			filters_.insert(filters_.begin(), NamedFilter("decimation", std::make_shared<rs2::decimation_filter>()));		}		if (use_colorizer_filter) {			filters_.push_back(NamedFilter("colorizer", std::make_shared<rs2::colorizer>()));			image_format_[DEPTH.first] = image_format_[COLOR.first];			unit_step_size_[DEPTH.first] = unit_step_size_[COLOR.first];			width_[DEPTH] = width_[COLOR];			height_[DEPTH] = height_[COLOR];			image_[DEPTH] = cv::Mat(std::max(0, height_[DEPTH]), std::max(0, width_[DEPTH]),				image_format_[DEPTH.first], cv::Scalar(0, 0, 0));		}		if (pointcloud_) {			filters_.push_back(NamedFilter("pointcloud",				std::make_shared<rs2::pointcloud>(pointcloud_texture_.first, pointcloud_texture_.second)));		}		LOG_COUT << "num_filters: " << filters_.size() << endl;	}	void clip_depth(rs2::depth_frame depth_frame, float clipping_dist)	{		uint16_t* p_depth_frame = reinterpret_cast<uint16_t*>(const_cast<void*>(depth_frame.get_data()));		uint16_t clipping_value = static_cast<uint16_t>(clipping_dist / depth_scale_meters_);		int width = depth_frame.get_width();		int height = depth_frame.get_height();		for (int y = 0; y < height; y++)		{			auto depth_pixel_index = y * width;			for (int x = 0; x < width; x++, ++depth_pixel_index)			{				// Check if the depth value is greater than the threashold				if (p_depth_frame[depth_pixel_index] > clipping_value)				{					p_depth_frame[depth_pixel_index] = 0; //Set to invalid (<=0) value.				}			}		}	}	bool valid() {		return device_;	}	rs2::device device_;	rs2::context context_;	std::string serial_no_;	rs2::pipeline pipe_;	rs2::pointcloud pc_;	rs2::points points_;	std::vector<rs2::sensor> dev_sensors_;	std::map<stream_index_pair, rs2::sensor> sensors_;	std::string filters_str_;	std::vector<NamedFilter> filters_;	std::shared_ptr<rs2::align> align_;	std::map<stream_index_pair, int> width_;	std::map<stream_index_pair, int> height_;	std::map<stream_index_pair, int> fps_;	std::map<rs2_stream, rs2_format> format_;	std::map<rs2_stream, int> image_format_;	std::map<stream_index_pair, std::vector<rs2::stream_profile>> enabled_profiles_;	std::map<stream_index_pair, cv::Mat> image_;	std::map<stream_index_pair, cv::Mat> depth_aligned_image_;	std::map<stream_index_pair, cv::Mat> depth_scaled_image_;	std::map<rs2_stream, int> unit_step_size_;	stream_index_pair pointcloud_texture_;	bool pointcloud_ = POINTCLOUD;	bool align_depth_ = ALIGN_DEPTH;	float clipping_distance_ = -1.0f;	float depth_scale_meters_ = 0.001f;	RsCameraDataParser data_parser_;};auto SensorRsCamera::start() -> void { Sensor::start(); }auto SensorRsCamera::stop() -> void { Sensor::stop(); }auto SensorRsCamera::valid() -> bool {	return imp_->valid();}auto SensorRsCamera::getImageStreamProfile(stream_index_pair elem) -> rs2::video_stream_profile {	return imp_->enabled_profiles_[elem].front().as<rs2::video_stream_profile>();}auto SensorRsCamera::init() -> void {	imp_->initialize();	Sensor::init();}auto SensorRsCamera::release() -> void { Sensor::release(); }auto SensorRsCamera::updateData(core::Msg& data) -> void {	rs2::frameset frameset = imp_->pipe_.wait_for_frames();	rs2::depth_frame depth_frame = frameset.get_depth_frame();	if (depth_frame && imp_->clipping_distance_ > 0) {		imp_->clip_depth(depth_frame, imp_->clipping_distance_);	}	if (imp_->align_depth_) {		frameset.apply_filter(*imp_->align_);	}	for (auto filter_it = imp_->filters_.begin(); filter_it != imp_->filters_.end(); filter_it++) {		frameset = filter_it->filter_->process(frameset);	}	processFrame(depth_frame, DEPTH, imp_->image_);	rs2::video_frame video_frame = frameset.get_color_frame();	processFrame(video_frame, COLOR, imp_->image_);	imp_->points_ = imp_->pc_.calculate(depth_frame);	//auto& image = imp_->image_[COLOR];	//size_t size = image.cols * image.elemSize() * image.rows;	//if (data.size() != size) {	//	data.resize(size);	//}	//memcpy(data.data(), image.data, size);	imp_->data_parser_.copyTo(this, COLOR, video_frame, data);	imp_->data_parser_.copyTo(this, DEPTH, depth_frame, data);	imp_->data_parser_.copyTo(this, POINT_CLOUD, imp_->points_, data);}void SensorRsCamera::processFrame(rs2::frame f, const stream_index_pair& stream, std::map<stream_index_pair, cv::Mat>& images) {	unsigned int width = 0;	unsigned int height = 0;	// bytes per pixel	auto bpp = 1;	if (f.is<rs2::video_frame>()) {		auto image = f.as<rs2::video_frame>();		width = image.get_width();		height = image.get_height();		bpp = image.get_bytes_per_pixel();	}	auto& image = images[stream];	if (images[stream].size() != cv::Size(width, height)) {		image.create(height, width, image.type());	}	image.data = (uint8_t*)f.get_data();	if (f.is<rs2::depth_frame>()) {		image = fixDepthScale(image, imp_->depth_scaled_image_[stream]);	}}cv::Mat& SensorRsCamera::fixDepthScale(const cv::Mat& from_image, cv::Mat& to_image) {	static const float meter_to_mm = 0.001f;	if (fabs(imp_->depth_scale_meters_ - meter_to_mm) < 1e-6)	{		to_image = from_image;		return to_image;	}	if (to_image.size() != from_image.size())	{		to_image.create(from_image.rows, from_image.cols, from_image.type());	}	CV_Assert(from_image.depth() == imp_->image_format_[RS2_STREAM_DEPTH]);	int nRows = from_image.rows;	int nCols = from_image.cols;	if (from_image.isContinuous())	{		nCols *= nRows;		nRows = 1;	}	int i, j;	const uint16_t* p_from;	uint16_t* p_to;	for (i = 0; i < nRows; ++i)	{		p_from = from_image.ptr<uint16_t>(i);		p_to = to_image.ptr<uint16_t>(i);		for (j = 0; j < nCols; ++j)		{			p_to[j] = (uint16_t)(p_from[j] * imp_->depth_scale_meters_ / meter_to_mm);		}	}	return to_image;}auto SensorRsCamera::loadXml(const core::XmlElement& xml_ele) -> void {}auto SensorRsCamera::saveXml(core::XmlElement& xml_ele) const -> void {}SensorRsCamera::SensorRsCamera(const std::string& name,	const std::string& serial_no, const Size& length)	: Sensor(name, length), imp_(new Imp()) {	imp_->serial_no_ = serial_no;	imp_->format_[RS2_STREAM_DEPTH] = RS2_FORMAT_Z16;	imp_->image_format_[RS2_STREAM_DEPTH] = CV_16UC1;	imp_->unit_step_size_[RS2_STREAM_DEPTH] = sizeof(uint16_t);	imp_->format_[RS2_STREAM_COLOR] = RS2_FORMAT_BGR8;	imp_->image_format_[RS2_STREAM_COLOR] = CV_8UC3;	imp_->unit_step_size_[RS2_STREAM_COLOR] = 3;	for (auto& stream : IMAGE_STREAMS) {		imp_->width_[stream] = IMAGE_WIDTH;		imp_->height_[stream] = IMAGE_HEIGHT;		imp_->image_[stream] = cv::Mat(imp_->height_[stream],			imp_->width_[stream], imp_->image_format_[stream.first], cv::Scalar(0, 0, 0));	}	imp_->align_ = std::make_shared<rs2::align>(RS2_STREAM_COLOR);	imp_->depth_aligned_image_[DEPTH] = cv::Mat(imp_->height_[DEPTH], imp_->width_[DEPTH],		imp_->image_format_[DEPTH.first], cv::Scalar(0, 0, 0));	imp_->depth_scaled_image_[DEPTH] = cv::Mat(imp_->height_[DEPTH], imp_->width_[DEPTH],		imp_->image_format_[DEPTH.first], cv::Scalar(0, 0, 0));	imp_->pointcloud_texture_ = stream_index_pair{ RS2_STREAM_COLOR, 0 };}SensorRsCamera::~SensorRsCamera() = default;}  // namespace codeit::sensor